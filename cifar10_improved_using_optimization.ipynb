{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cifar10_improved_using_optimization.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPY35reRpAyO7kgKjBEmjQa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andres8bit/Machine-Learning/blob/main/cifar10_improved_using_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UodkGMyPEsjK"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Dense,Activation, Flatten, Dropout,BatchNormalization, Conv2D, MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import regularizers, optimizers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy2yIEBOH5FI"
      },
      "source": [
        "def normalize_images(items):\n",
        "  temp = np.zeros(shape=(items.shape))\n",
        "  mean = np.mean(items,axis=(0,1,2,3))\n",
        "  std = np.std(items,axis=(0,1,2,3))\n",
        "  temp =(items - mean) /(std +1e-7)\n",
        "  return temp"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbKffRiWMGoW"
      },
      "source": [
        "def display_loss(model):\n",
        "  loss = model.history['loss']\n",
        "  val_loss = model.history['val_loss']\n",
        "\n",
        "  plt.figure()\n",
        "  plt.plot(model.epoch, loss, 'r',label='Training loss')\n",
        "  plt.plot(model.epoch,val_loss,'bo',label='Validation loss')\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss Value')\n",
        "  plt.ylim([0,1])\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMjhCxtEGLAM",
        "outputId": "4937e45d-9ca6-4143-9e86-c8f35c73a30b"
      },
      "source": [
        "(x_train,y_train), (x_test,y_test) = cifar10.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWcB9lu3GYgL"
      },
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cI3qmMvHDrP"
      },
      "source": [
        "(x_train,x_valid) = x_train[5000:],x_train[:5000]\n",
        "(y_train, y_valid) = y_train[5000:],y_train[:5000]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDxoBKNjHiKA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40ce85ae-45c0-4881-f87a-eeee354f6d79"
      },
      "source": [
        "# Training, Test, and validation data split:\n",
        "print('x_train = ',x_train.shape)\n",
        "print('x_valid = ',x_valid.shape)\n",
        "print('x_test = ',x_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train =  (45000, 32, 32, 3)\n",
            "x_valid =  (5000, 32, 32, 3)\n",
            "x_test =  (10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLLweG0Pa7Iz",
        "outputId": "2f043150-aa39-480d-b77d-2aaf6de1fce6"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(45000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCVSOYj2ImJx"
      },
      "source": [
        "\n",
        "# Data Normalization:\n",
        "x_train = normalize_images(x_train)\n",
        "x_valid = normalize_images(x_valid)\n",
        "x_test = normalize_images(x_test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3MVfNBJKHmZ"
      },
      "source": [
        "# One-Hot Encocding of lables:\n",
        "y_train = np_utils.to_categorical(y_train,10)\n",
        "y_valid = np_utils.to_categorical(y_valid,10)\n",
        "y_test = np_utils.to_categorical(y_test,10)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5Gy1V2yLbXK"
      },
      "source": [
        "# Data Augmentation:\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    vertical_flip=False\n",
        ")\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDfuEKuJMIMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abd76ea4-cadb-4c3c-bd3f-8309c39a18e9"
      },
      "source": [
        "# Mode Variables:\n",
        "base_hidden_units = 32\n",
        "weight_decay= 1e-4\n",
        "\n",
        "# Model Architecture Sequentional API based:\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolution:\n",
        "model.add(Conv2D(base_hidden_units,kernel_size=3,padding='same',\n",
        "                 kernel_regularizer=regularizers.l2(weight_decay), \n",
        "                 input_shape=x_train.shape[1:]))\n",
        "# Relu is our main activation function\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalization will be applied to each Convolutional layer\n",
        "model.add(BatchNormalization()) \n",
        "\n",
        "# 2nd Convolution:\n",
        "model.add(Conv2D(base_hidden_units,kernel_size=3,padding='same',\n",
        "                 kernel_regularizer=regularizers.L2(weight_decay)))\n",
        "# Activation:\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalization:\n",
        "model.add(BatchNormalization())\n",
        "# Pool & Dropout:\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# 3rd Convolution:\n",
        "model.add(Conv2D(base_hidden_units*2, kernel_size=3,padding='same',\n",
        "                 kernel_regularizer=regularizers.L2(weight_decay)))\n",
        "# Activation:\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normalization:\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 4rd Convolution:\n",
        "model.add(Conv2D(base_hidden_units * 2,kernel_size=3,padding='same',\n",
        "                 kernel_regularizer=regularizers.L2(weight_decay)))\n",
        "# Activation\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normaliation:\n",
        "model.add(BatchNormalization())\n",
        "# Pool & Dropout:\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# 5th Convolution:\n",
        "model.add(Conv2D(base_hidden_units * 4,kernel_size=3,padding='same',\n",
        "                 kernel_regularizer=regularizers.L2(weight_decay)))\n",
        "# Activation\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normaliation:\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# 6th Convolution:\n",
        "model.add(Conv2D(base_hidden_units * 4,kernel_size=3,padding='same',\n",
        "                 kernel_regularizer=regularizers.L2(weight_decay)))\n",
        "# Activation\n",
        "model.add(Activation('relu'))\n",
        "# Batch Normaliation:\n",
        "model.add(BatchNormalization())\n",
        "# Pool & Dropout:\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# Final Fully Connected Layer:\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6ZQmvG3UBCV",
        "outputId": "955de5a2-0dc0-4f07-d90c-8c8624b72a0b"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 200\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.100epochs.hdfs',verbose=1,save_best_only=True)\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.0001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
        "history = model.fit(datagen.flow(x_train,y_train,batch_size=batch_size)\n",
        "                              ,callbacks=[checkpointer],steps_per_epoch=x_train.shape[0]//batch_size,\n",
        "                              epochs=epochs,verbose=2,validation_data=(x_valid,y_valid))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "351/351 - 64s - loss: 2.8264 - accuracy: 0.2651 - val_loss: 2.0666 - val_accuracy: 0.2796\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2.06659, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 2/200\n",
            "351/351 - 17s - loss: 2.0968 - accuracy: 0.3533 - val_loss: 1.5476 - val_accuracy: 0.4718\n",
            "\n",
            "Epoch 00002: val_loss improved from 2.06659 to 1.54759, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 3/200\n",
            "351/351 - 17s - loss: 1.8558 - accuracy: 0.4038 - val_loss: 1.5219 - val_accuracy: 0.4770\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.54759 to 1.52188, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 4/200\n",
            "351/351 - 17s - loss: 1.7263 - accuracy: 0.4417 - val_loss: 1.4894 - val_accuracy: 0.4890\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.52188 to 1.48944, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 5/200\n",
            "351/351 - 17s - loss: 1.6296 - accuracy: 0.4701 - val_loss: 1.4237 - val_accuracy: 0.5092\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.48944 to 1.42375, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 6/200\n",
            "351/351 - 17s - loss: 1.5476 - accuracy: 0.4943 - val_loss: 1.4222 - val_accuracy: 0.5192\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.42375 to 1.42216, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 7/200\n",
            "351/351 - 17s - loss: 1.4783 - accuracy: 0.5140 - val_loss: 1.3170 - val_accuracy: 0.5540\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.42216 to 1.31705, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 8/200\n",
            "351/351 - 17s - loss: 1.4108 - accuracy: 0.5347 - val_loss: 1.3988 - val_accuracy: 0.5398\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.31705\n",
            "Epoch 9/200\n",
            "351/351 - 17s - loss: 1.3458 - accuracy: 0.5542 - val_loss: 1.3197 - val_accuracy: 0.5692\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.31705\n",
            "Epoch 10/200\n",
            "351/351 - 17s - loss: 1.2919 - accuracy: 0.5749 - val_loss: 1.2874 - val_accuracy: 0.5758\n",
            "\n",
            "Epoch 00010: val_loss improved from 1.31705 to 1.28743, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 11/200\n",
            "351/351 - 17s - loss: 1.2529 - accuracy: 0.5867 - val_loss: 1.1660 - val_accuracy: 0.6136\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.28743 to 1.16603, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 12/200\n",
            "351/351 - 17s - loss: 1.2006 - accuracy: 0.6029 - val_loss: 1.1830 - val_accuracy: 0.6066\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.16603\n",
            "Epoch 13/200\n",
            "351/351 - 17s - loss: 1.1725 - accuracy: 0.6122 - val_loss: 1.1883 - val_accuracy: 0.6086\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.16603\n",
            "Epoch 14/200\n",
            "351/351 - 17s - loss: 1.1296 - accuracy: 0.6233 - val_loss: 1.2052 - val_accuracy: 0.6088\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.16603\n",
            "Epoch 15/200\n",
            "351/351 - 17s - loss: 1.0997 - accuracy: 0.6348 - val_loss: 1.0735 - val_accuracy: 0.6480\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.16603 to 1.07348, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 16/200\n",
            "351/351 - 17s - loss: 1.0644 - accuracy: 0.6456 - val_loss: 1.1173 - val_accuracy: 0.6374\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.07348\n",
            "Epoch 17/200\n",
            "351/351 - 17s - loss: 1.0361 - accuracy: 0.6549 - val_loss: 1.0034 - val_accuracy: 0.6776\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.07348 to 1.00338, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 18/200\n",
            "351/351 - 17s - loss: 1.0104 - accuracy: 0.6664 - val_loss: 1.0090 - val_accuracy: 0.6774\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.00338\n",
            "Epoch 19/200\n",
            "351/351 - 17s - loss: 0.9924 - accuracy: 0.6680 - val_loss: 0.9937 - val_accuracy: 0.6826\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.00338 to 0.99373, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 20/200\n",
            "351/351 - 17s - loss: 0.9677 - accuracy: 0.6736 - val_loss: 0.9853 - val_accuracy: 0.6794\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.99373 to 0.98531, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 21/200\n",
            "351/351 - 17s - loss: 0.9393 - accuracy: 0.6849 - val_loss: 0.9613 - val_accuracy: 0.6930\n",
            "\n",
            "Epoch 00021: val_loss improved from 0.98531 to 0.96125, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 22/200\n",
            "351/351 - 17s - loss: 0.9231 - accuracy: 0.6947 - val_loss: 0.8863 - val_accuracy: 0.7100\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.96125 to 0.88634, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 23/200\n",
            "351/351 - 17s - loss: 0.9009 - accuracy: 0.6983 - val_loss: 0.8820 - val_accuracy: 0.7146\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.88634 to 0.88198, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 24/200\n",
            "351/351 - 17s - loss: 0.8898 - accuracy: 0.7026 - val_loss: 0.8809 - val_accuracy: 0.7244\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.88198 to 0.88093, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 25/200\n",
            "351/351 - 17s - loss: 0.8709 - accuracy: 0.7090 - val_loss: 0.8860 - val_accuracy: 0.7136\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.88093\n",
            "Epoch 26/200\n",
            "351/351 - 17s - loss: 0.8533 - accuracy: 0.7151 - val_loss: 0.8581 - val_accuracy: 0.7244\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.88093 to 0.85809, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 27/200\n",
            "351/351 - 17s - loss: 0.8368 - accuracy: 0.7204 - val_loss: 0.8457 - val_accuracy: 0.7306\n",
            "\n",
            "Epoch 00027: val_loss improved from 0.85809 to 0.84574, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 28/200\n",
            "351/351 - 17s - loss: 0.8325 - accuracy: 0.7215 - val_loss: 0.8868 - val_accuracy: 0.7176\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.84574\n",
            "Epoch 29/200\n",
            "351/351 - 17s - loss: 0.8072 - accuracy: 0.7287 - val_loss: 0.8003 - val_accuracy: 0.7392\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.84574 to 0.80035, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 30/200\n",
            "351/351 - 17s - loss: 0.8024 - accuracy: 0.7330 - val_loss: 0.7789 - val_accuracy: 0.7480\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.80035 to 0.77890, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 31/200\n",
            "351/351 - 17s - loss: 0.7935 - accuracy: 0.7326 - val_loss: 0.7859 - val_accuracy: 0.7516\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.77890\n",
            "Epoch 32/200\n",
            "351/351 - 17s - loss: 0.7789 - accuracy: 0.7396 - val_loss: 0.8119 - val_accuracy: 0.7444\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.77890\n",
            "Epoch 33/200\n",
            "351/351 - 17s - loss: 0.7646 - accuracy: 0.7445 - val_loss: 0.7653 - val_accuracy: 0.7556\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.77890 to 0.76525, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 34/200\n",
            "351/351 - 17s - loss: 0.7573 - accuracy: 0.7487 - val_loss: 0.7668 - val_accuracy: 0.7538\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.76525\n",
            "Epoch 35/200\n",
            "351/351 - 17s - loss: 0.7410 - accuracy: 0.7539 - val_loss: 0.6889 - val_accuracy: 0.7794\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.76525 to 0.68890, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 36/200\n",
            "351/351 - 17s - loss: 0.7306 - accuracy: 0.7577 - val_loss: 0.6930 - val_accuracy: 0.7760\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.68890\n",
            "Epoch 37/200\n",
            "351/351 - 17s - loss: 0.7283 - accuracy: 0.7580 - val_loss: 0.7239 - val_accuracy: 0.7684\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.68890\n",
            "Epoch 38/200\n",
            "351/351 - 17s - loss: 0.7184 - accuracy: 0.7610 - val_loss: 0.7363 - val_accuracy: 0.7704\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.68890\n",
            "Epoch 39/200\n",
            "351/351 - 17s - loss: 0.7069 - accuracy: 0.7653 - val_loss: 0.6730 - val_accuracy: 0.7898\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.68890 to 0.67298, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 40/200\n",
            "351/351 - 17s - loss: 0.7015 - accuracy: 0.7683 - val_loss: 0.6824 - val_accuracy: 0.7854\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.67298\n",
            "Epoch 41/200\n",
            "351/351 - 17s - loss: 0.6901 - accuracy: 0.7719 - val_loss: 0.6734 - val_accuracy: 0.7868\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.67298\n",
            "Epoch 42/200\n",
            "351/351 - 17s - loss: 0.6824 - accuracy: 0.7750 - val_loss: 0.7136 - val_accuracy: 0.7802\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.67298\n",
            "Epoch 43/200\n",
            "351/351 - 17s - loss: 0.6732 - accuracy: 0.7745 - val_loss: 0.6587 - val_accuracy: 0.7942\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.67298 to 0.65873, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 44/200\n",
            "351/351 - 17s - loss: 0.6661 - accuracy: 0.7783 - val_loss: 0.6973 - val_accuracy: 0.7848\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.65873\n",
            "Epoch 45/200\n",
            "351/351 - 17s - loss: 0.6632 - accuracy: 0.7815 - val_loss: 0.6385 - val_accuracy: 0.7984\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.65873 to 0.63850, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 46/200\n",
            "351/351 - 17s - loss: 0.6539 - accuracy: 0.7846 - val_loss: 0.6838 - val_accuracy: 0.7858\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.63850\n",
            "Epoch 47/200\n",
            "351/351 - 17s - loss: 0.6430 - accuracy: 0.7856 - val_loss: 0.6518 - val_accuracy: 0.7964\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.63850\n",
            "Epoch 48/200\n",
            "351/351 - 17s - loss: 0.6336 - accuracy: 0.7906 - val_loss: 0.6681 - val_accuracy: 0.7922\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.63850\n",
            "Epoch 49/200\n",
            "351/351 - 17s - loss: 0.6247 - accuracy: 0.7944 - val_loss: 0.6129 - val_accuracy: 0.8036\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.63850 to 0.61286, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 50/200\n",
            "351/351 - 17s - loss: 0.6283 - accuracy: 0.7896 - val_loss: 0.6660 - val_accuracy: 0.7970\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.61286\n",
            "Epoch 51/200\n",
            "351/351 - 17s - loss: 0.6208 - accuracy: 0.7933 - val_loss: 0.5840 - val_accuracy: 0.8148\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.61286 to 0.58396, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 52/200\n",
            "351/351 - 17s - loss: 0.6098 - accuracy: 0.7997 - val_loss: 0.6287 - val_accuracy: 0.8052\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.58396\n",
            "Epoch 53/200\n",
            "351/351 - 17s - loss: 0.6068 - accuracy: 0.8005 - val_loss: 0.6000 - val_accuracy: 0.8128\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.58396\n",
            "Epoch 54/200\n",
            "351/351 - 17s - loss: 0.5999 - accuracy: 0.8028 - val_loss: 0.6292 - val_accuracy: 0.8076\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.58396\n",
            "Epoch 55/200\n",
            "351/351 - 17s - loss: 0.5950 - accuracy: 0.8029 - val_loss: 0.6053 - val_accuracy: 0.8148\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.58396\n",
            "Epoch 56/200\n",
            "351/351 - 17s - loss: 0.5845 - accuracy: 0.8071 - val_loss: 0.5873 - val_accuracy: 0.8150\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.58396\n",
            "Epoch 57/200\n",
            "351/351 - 17s - loss: 0.5808 - accuracy: 0.8091 - val_loss: 0.5919 - val_accuracy: 0.8148\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.58396\n",
            "Epoch 58/200\n",
            "351/351 - 17s - loss: 0.5817 - accuracy: 0.8077 - val_loss: 0.6015 - val_accuracy: 0.8124\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.58396\n",
            "Epoch 59/200\n",
            "351/351 - 17s - loss: 0.5718 - accuracy: 0.8136 - val_loss: 0.5574 - val_accuracy: 0.8222\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.58396 to 0.55735, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 60/200\n",
            "351/351 - 17s - loss: 0.5722 - accuracy: 0.8109 - val_loss: 0.5963 - val_accuracy: 0.8130\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.55735\n",
            "Epoch 61/200\n",
            "351/351 - 17s - loss: 0.5563 - accuracy: 0.8182 - val_loss: 0.6166 - val_accuracy: 0.8136\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.55735\n",
            "Epoch 62/200\n",
            "351/351 - 17s - loss: 0.5600 - accuracy: 0.8165 - val_loss: 0.5985 - val_accuracy: 0.8126\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.55735\n",
            "Epoch 63/200\n",
            "351/351 - 17s - loss: 0.5527 - accuracy: 0.8156 - val_loss: 0.5810 - val_accuracy: 0.8198\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.55735\n",
            "Epoch 64/200\n",
            "351/351 - 17s - loss: 0.5526 - accuracy: 0.8200 - val_loss: 0.6012 - val_accuracy: 0.8158\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.55735\n",
            "Epoch 65/200\n",
            "351/351 - 17s - loss: 0.5528 - accuracy: 0.8210 - val_loss: 0.5907 - val_accuracy: 0.8154\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.55735\n",
            "Epoch 66/200\n",
            "351/351 - 17s - loss: 0.5448 - accuracy: 0.8192 - val_loss: 0.5897 - val_accuracy: 0.8168\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.55735\n",
            "Epoch 67/200\n",
            "351/351 - 17s - loss: 0.5381 - accuracy: 0.8245 - val_loss: 0.5604 - val_accuracy: 0.8272\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.55735\n",
            "Epoch 68/200\n",
            "351/351 - 17s - loss: 0.5277 - accuracy: 0.8250 - val_loss: 0.5579 - val_accuracy: 0.8270\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.55735\n",
            "Epoch 69/200\n",
            "351/351 - 17s - loss: 0.5307 - accuracy: 0.8252 - val_loss: 0.5576 - val_accuracy: 0.8290\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.55735\n",
            "Epoch 70/200\n",
            "351/351 - 17s - loss: 0.5247 - accuracy: 0.8270 - val_loss: 0.5561 - val_accuracy: 0.8294\n",
            "\n",
            "Epoch 00070: val_loss improved from 0.55735 to 0.55609, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 71/200\n",
            "351/351 - 17s - loss: 0.5204 - accuracy: 0.8293 - val_loss: 0.5584 - val_accuracy: 0.8274\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.55609\n",
            "Epoch 72/200\n",
            "351/351 - 17s - loss: 0.5171 - accuracy: 0.8297 - val_loss: 0.5486 - val_accuracy: 0.8314\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.55609 to 0.54864, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 73/200\n",
            "351/351 - 17s - loss: 0.5134 - accuracy: 0.8331 - val_loss: 0.5515 - val_accuracy: 0.8344\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.54864\n",
            "Epoch 74/200\n",
            "351/351 - 17s - loss: 0.5125 - accuracy: 0.8351 - val_loss: 0.5598 - val_accuracy: 0.8274\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.54864\n",
            "Epoch 75/200\n",
            "351/351 - 17s - loss: 0.5110 - accuracy: 0.8339 - val_loss: 0.5400 - val_accuracy: 0.8338\n",
            "\n",
            "Epoch 00075: val_loss improved from 0.54864 to 0.54005, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 76/200\n",
            "351/351 - 17s - loss: 0.5030 - accuracy: 0.8346 - val_loss: 0.5517 - val_accuracy: 0.8304\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.54005\n",
            "Epoch 77/200\n",
            "351/351 - 17s - loss: 0.5069 - accuracy: 0.8356 - val_loss: 0.5240 - val_accuracy: 0.8386\n",
            "\n",
            "Epoch 00077: val_loss improved from 0.54005 to 0.52401, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 78/200\n",
            "351/351 - 17s - loss: 0.5032 - accuracy: 0.8360 - val_loss: 0.5744 - val_accuracy: 0.8256\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.52401\n",
            "Epoch 79/200\n",
            "351/351 - 17s - loss: 0.4940 - accuracy: 0.8362 - val_loss: 0.5512 - val_accuracy: 0.8334\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.52401\n",
            "Epoch 80/200\n",
            "351/351 - 17s - loss: 0.4882 - accuracy: 0.8426 - val_loss: 0.5467 - val_accuracy: 0.8334\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.52401\n",
            "Epoch 81/200\n",
            "351/351 - 17s - loss: 0.4852 - accuracy: 0.8419 - val_loss: 0.5453 - val_accuracy: 0.8322\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.52401\n",
            "Epoch 82/200\n",
            "351/351 - 17s - loss: 0.4845 - accuracy: 0.8422 - val_loss: 0.5291 - val_accuracy: 0.8414\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.52401\n",
            "Epoch 83/200\n",
            "351/351 - 17s - loss: 0.4817 - accuracy: 0.8437 - val_loss: 0.5113 - val_accuracy: 0.8438\n",
            "\n",
            "Epoch 00083: val_loss improved from 0.52401 to 0.51129, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 84/200\n",
            "351/351 - 17s - loss: 0.4751 - accuracy: 0.8455 - val_loss: 0.5560 - val_accuracy: 0.8304\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.51129\n",
            "Epoch 85/200\n",
            "351/351 - 17s - loss: 0.4784 - accuracy: 0.8456 - val_loss: 0.5172 - val_accuracy: 0.8386\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.51129\n",
            "Epoch 86/200\n",
            "351/351 - 17s - loss: 0.4717 - accuracy: 0.8445 - val_loss: 0.5189 - val_accuracy: 0.8410\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.51129\n",
            "Epoch 87/200\n",
            "351/351 - 17s - loss: 0.4719 - accuracy: 0.8465 - val_loss: 0.5049 - val_accuracy: 0.8472\n",
            "\n",
            "Epoch 00087: val_loss improved from 0.51129 to 0.50492, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 88/200\n",
            "351/351 - 17s - loss: 0.4617 - accuracy: 0.8506 - val_loss: 0.5175 - val_accuracy: 0.8442\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.50492\n",
            "Epoch 89/200\n",
            "351/351 - 17s - loss: 0.4630 - accuracy: 0.8505 - val_loss: 0.5272 - val_accuracy: 0.8400\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.50492\n",
            "Epoch 90/200\n",
            "351/351 - 17s - loss: 0.4596 - accuracy: 0.8524 - val_loss: 0.5135 - val_accuracy: 0.8436\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.50492\n",
            "Epoch 91/200\n",
            "351/351 - 17s - loss: 0.4565 - accuracy: 0.8518 - val_loss: 0.5273 - val_accuracy: 0.8422\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.50492\n",
            "Epoch 92/200\n",
            "351/351 - 17s - loss: 0.4612 - accuracy: 0.8506 - val_loss: 0.5118 - val_accuracy: 0.8428\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.50492\n",
            "Epoch 93/200\n",
            "351/351 - 17s - loss: 0.4535 - accuracy: 0.8534 - val_loss: 0.5047 - val_accuracy: 0.8504\n",
            "\n",
            "Epoch 00093: val_loss improved from 0.50492 to 0.50469, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 94/200\n",
            "351/351 - 17s - loss: 0.4500 - accuracy: 0.8552 - val_loss: 0.5327 - val_accuracy: 0.8416\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.50469\n",
            "Epoch 95/200\n",
            "351/351 - 17s - loss: 0.4508 - accuracy: 0.8532 - val_loss: 0.4990 - val_accuracy: 0.8490\n",
            "\n",
            "Epoch 00095: val_loss improved from 0.50469 to 0.49903, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 96/200\n",
            "351/351 - 17s - loss: 0.4459 - accuracy: 0.8551 - val_loss: 0.5011 - val_accuracy: 0.8500\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.49903\n",
            "Epoch 97/200\n",
            "351/351 - 17s - loss: 0.4467 - accuracy: 0.8544 - val_loss: 0.5100 - val_accuracy: 0.8456\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.49903\n",
            "Epoch 98/200\n",
            "351/351 - 17s - loss: 0.4399 - accuracy: 0.8580 - val_loss: 0.4957 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00098: val_loss improved from 0.49903 to 0.49567, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 99/200\n",
            "351/351 - 17s - loss: 0.4435 - accuracy: 0.8548 - val_loss: 0.5195 - val_accuracy: 0.8462\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.49567\n",
            "Epoch 100/200\n",
            "351/351 - 17s - loss: 0.4417 - accuracy: 0.8596 - val_loss: 0.5040 - val_accuracy: 0.8510\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.49567\n",
            "Epoch 101/200\n",
            "351/351 - 17s - loss: 0.4359 - accuracy: 0.8584 - val_loss: 0.5005 - val_accuracy: 0.8496\n",
            "\n",
            "Epoch 00101: val_loss did not improve from 0.49567\n",
            "Epoch 102/200\n",
            "351/351 - 17s - loss: 0.4340 - accuracy: 0.8606 - val_loss: 0.4909 - val_accuracy: 0.8536\n",
            "\n",
            "Epoch 00102: val_loss improved from 0.49567 to 0.49088, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 103/200\n",
            "351/351 - 17s - loss: 0.4326 - accuracy: 0.8619 - val_loss: 0.4819 - val_accuracy: 0.8528\n",
            "\n",
            "Epoch 00103: val_loss improved from 0.49088 to 0.48189, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 104/200\n",
            "351/351 - 17s - loss: 0.4292 - accuracy: 0.8619 - val_loss: 0.4935 - val_accuracy: 0.8512\n",
            "\n",
            "Epoch 00104: val_loss did not improve from 0.48189\n",
            "Epoch 105/200\n",
            "351/351 - 17s - loss: 0.4290 - accuracy: 0.8613 - val_loss: 0.4796 - val_accuracy: 0.8566\n",
            "\n",
            "Epoch 00105: val_loss improved from 0.48189 to 0.47958, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 106/200\n",
            "351/351 - 17s - loss: 0.4221 - accuracy: 0.8643 - val_loss: 0.5233 - val_accuracy: 0.8432\n",
            "\n",
            "Epoch 00106: val_loss did not improve from 0.47958\n",
            "Epoch 107/200\n",
            "351/351 - 17s - loss: 0.4243 - accuracy: 0.8636 - val_loss: 0.5128 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00107: val_loss did not improve from 0.47958\n",
            "Epoch 108/200\n",
            "351/351 - 17s - loss: 0.4214 - accuracy: 0.8645 - val_loss: 0.5079 - val_accuracy: 0.8474\n",
            "\n",
            "Epoch 00108: val_loss did not improve from 0.47958\n",
            "Epoch 109/200\n",
            "351/351 - 17s - loss: 0.4251 - accuracy: 0.8629 - val_loss: 0.5061 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00109: val_loss did not improve from 0.47958\n",
            "Epoch 110/200\n",
            "351/351 - 17s - loss: 0.4233 - accuracy: 0.8635 - val_loss: 0.5080 - val_accuracy: 0.8516\n",
            "\n",
            "Epoch 00110: val_loss did not improve from 0.47958\n",
            "Epoch 111/200\n",
            "351/351 - 17s - loss: 0.4159 - accuracy: 0.8670 - val_loss: 0.4920 - val_accuracy: 0.8576\n",
            "\n",
            "Epoch 00111: val_loss did not improve from 0.47958\n",
            "Epoch 112/200\n",
            "351/351 - 17s - loss: 0.4094 - accuracy: 0.8686 - val_loss: 0.5128 - val_accuracy: 0.8488\n",
            "\n",
            "Epoch 00112: val_loss did not improve from 0.47958\n",
            "Epoch 113/200\n",
            "351/351 - 17s - loss: 0.4026 - accuracy: 0.8702 - val_loss: 0.5260 - val_accuracy: 0.8492\n",
            "\n",
            "Epoch 00113: val_loss did not improve from 0.47958\n",
            "Epoch 114/200\n",
            "351/351 - 17s - loss: 0.4090 - accuracy: 0.8690 - val_loss: 0.4934 - val_accuracy: 0.8486\n",
            "\n",
            "Epoch 00114: val_loss did not improve from 0.47958\n",
            "Epoch 115/200\n",
            "351/351 - 17s - loss: 0.4081 - accuracy: 0.8671 - val_loss: 0.5031 - val_accuracy: 0.8518\n",
            "\n",
            "Epoch 00115: val_loss did not improve from 0.47958\n",
            "Epoch 116/200\n",
            "351/351 - 17s - loss: 0.4065 - accuracy: 0.8707 - val_loss: 0.4916 - val_accuracy: 0.8530\n",
            "\n",
            "Epoch 00116: val_loss did not improve from 0.47958\n",
            "Epoch 117/200\n",
            "351/351 - 17s - loss: 0.4034 - accuracy: 0.8709 - val_loss: 0.4866 - val_accuracy: 0.8546\n",
            "\n",
            "Epoch 00117: val_loss did not improve from 0.47958\n",
            "Epoch 118/200\n",
            "351/351 - 17s - loss: 0.4061 - accuracy: 0.8689 - val_loss: 0.4981 - val_accuracy: 0.8550\n",
            "\n",
            "Epoch 00118: val_loss did not improve from 0.47958\n",
            "Epoch 119/200\n",
            "351/351 - 17s - loss: 0.4006 - accuracy: 0.8716 - val_loss: 0.4746 - val_accuracy: 0.8582\n",
            "\n",
            "Epoch 00119: val_loss improved from 0.47958 to 0.47460, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 120/200\n",
            "351/351 - 17s - loss: 0.4024 - accuracy: 0.8695 - val_loss: 0.5187 - val_accuracy: 0.8488\n",
            "\n",
            "Epoch 00120: val_loss did not improve from 0.47460\n",
            "Epoch 121/200\n",
            "351/351 - 17s - loss: 0.3982 - accuracy: 0.8734 - val_loss: 0.5249 - val_accuracy: 0.8426\n",
            "\n",
            "Epoch 00121: val_loss did not improve from 0.47460\n",
            "Epoch 122/200\n",
            "351/351 - 17s - loss: 0.3921 - accuracy: 0.8753 - val_loss: 0.4877 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00122: val_loss did not improve from 0.47460\n",
            "Epoch 123/200\n",
            "351/351 - 17s - loss: 0.3990 - accuracy: 0.8714 - val_loss: 0.4703 - val_accuracy: 0.8586\n",
            "\n",
            "Epoch 00123: val_loss improved from 0.47460 to 0.47028, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 124/200\n",
            "351/351 - 17s - loss: 0.3902 - accuracy: 0.8751 - val_loss: 0.4962 - val_accuracy: 0.8528\n",
            "\n",
            "Epoch 00124: val_loss did not improve from 0.47028\n",
            "Epoch 125/200\n",
            "351/351 - 17s - loss: 0.3912 - accuracy: 0.8743 - val_loss: 0.4919 - val_accuracy: 0.8542\n",
            "\n",
            "Epoch 00125: val_loss did not improve from 0.47028\n",
            "Epoch 126/200\n",
            "351/351 - 17s - loss: 0.3913 - accuracy: 0.8734 - val_loss: 0.4777 - val_accuracy: 0.8578\n",
            "\n",
            "Epoch 00126: val_loss did not improve from 0.47028\n",
            "Epoch 127/200\n",
            "351/351 - 17s - loss: 0.3877 - accuracy: 0.8738 - val_loss: 0.4864 - val_accuracy: 0.8552\n",
            "\n",
            "Epoch 00127: val_loss did not improve from 0.47028\n",
            "Epoch 128/200\n",
            "351/351 - 17s - loss: 0.3881 - accuracy: 0.8751 - val_loss: 0.4740 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00128: val_loss did not improve from 0.47028\n",
            "Epoch 129/200\n",
            "351/351 - 17s - loss: 0.3845 - accuracy: 0.8775 - val_loss: 0.4845 - val_accuracy: 0.8566\n",
            "\n",
            "Epoch 00129: val_loss did not improve from 0.47028\n",
            "Epoch 130/200\n",
            "351/351 - 17s - loss: 0.3839 - accuracy: 0.8775 - val_loss: 0.5438 - val_accuracy: 0.8418\n",
            "\n",
            "Epoch 00130: val_loss did not improve from 0.47028\n",
            "Epoch 131/200\n",
            "351/351 - 17s - loss: 0.3812 - accuracy: 0.8777 - val_loss: 0.4882 - val_accuracy: 0.8548\n",
            "\n",
            "Epoch 00131: val_loss did not improve from 0.47028\n",
            "Epoch 132/200\n",
            "351/351 - 17s - loss: 0.3808 - accuracy: 0.8791 - val_loss: 0.4666 - val_accuracy: 0.8612\n",
            "\n",
            "Epoch 00132: val_loss improved from 0.47028 to 0.46664, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 133/200\n",
            "351/351 - 17s - loss: 0.3841 - accuracy: 0.8780 - val_loss: 0.4744 - val_accuracy: 0.8586\n",
            "\n",
            "Epoch 00133: val_loss did not improve from 0.46664\n",
            "Epoch 134/200\n",
            "351/351 - 17s - loss: 0.3791 - accuracy: 0.8803 - val_loss: 0.5141 - val_accuracy: 0.8522\n",
            "\n",
            "Epoch 00134: val_loss did not improve from 0.46664\n",
            "Epoch 135/200\n",
            "351/351 - 17s - loss: 0.3775 - accuracy: 0.8791 - val_loss: 0.4832 - val_accuracy: 0.8594\n",
            "\n",
            "Epoch 00135: val_loss did not improve from 0.46664\n",
            "Epoch 136/200\n",
            "351/351 - 17s - loss: 0.3769 - accuracy: 0.8805 - val_loss: 0.4775 - val_accuracy: 0.8582\n",
            "\n",
            "Epoch 00136: val_loss did not improve from 0.46664\n",
            "Epoch 137/200\n",
            "351/351 - 17s - loss: 0.3760 - accuracy: 0.8806 - val_loss: 0.4705 - val_accuracy: 0.8620\n",
            "\n",
            "Epoch 00137: val_loss did not improve from 0.46664\n",
            "Epoch 138/200\n",
            "351/351 - 17s - loss: 0.3723 - accuracy: 0.8822 - val_loss: 0.5098 - val_accuracy: 0.8536\n",
            "\n",
            "Epoch 00138: val_loss did not improve from 0.46664\n",
            "Epoch 139/200\n",
            "351/351 - 17s - loss: 0.3715 - accuracy: 0.8811 - val_loss: 0.4779 - val_accuracy: 0.8536\n",
            "\n",
            "Epoch 00139: val_loss did not improve from 0.46664\n",
            "Epoch 140/200\n",
            "351/351 - 17s - loss: 0.3762 - accuracy: 0.8809 - val_loss: 0.4876 - val_accuracy: 0.8542\n",
            "\n",
            "Epoch 00140: val_loss did not improve from 0.46664\n",
            "Epoch 141/200\n",
            "351/351 - 17s - loss: 0.3686 - accuracy: 0.8810 - val_loss: 0.5045 - val_accuracy: 0.8544\n",
            "\n",
            "Epoch 00141: val_loss did not improve from 0.46664\n",
            "Epoch 142/200\n",
            "351/351 - 17s - loss: 0.3679 - accuracy: 0.8828 - val_loss: 0.4776 - val_accuracy: 0.8588\n",
            "\n",
            "Epoch 00142: val_loss did not improve from 0.46664\n",
            "Epoch 143/200\n",
            "351/351 - 17s - loss: 0.3684 - accuracy: 0.8824 - val_loss: 0.4776 - val_accuracy: 0.8590\n",
            "\n",
            "Epoch 00143: val_loss did not improve from 0.46664\n",
            "Epoch 144/200\n",
            "351/351 - 17s - loss: 0.3658 - accuracy: 0.8845 - val_loss: 0.4816 - val_accuracy: 0.8588\n",
            "\n",
            "Epoch 00144: val_loss did not improve from 0.46664\n",
            "Epoch 145/200\n",
            "351/351 - 17s - loss: 0.3559 - accuracy: 0.8874 - val_loss: 0.4829 - val_accuracy: 0.8604\n",
            "\n",
            "Epoch 00145: val_loss did not improve from 0.46664\n",
            "Epoch 146/200\n",
            "351/351 - 17s - loss: 0.3564 - accuracy: 0.8876 - val_loss: 0.5005 - val_accuracy: 0.8554\n",
            "\n",
            "Epoch 00146: val_loss did not improve from 0.46664\n",
            "Epoch 147/200\n",
            "351/351 - 17s - loss: 0.3610 - accuracy: 0.8857 - val_loss: 0.4948 - val_accuracy: 0.8534\n",
            "\n",
            "Epoch 00147: val_loss did not improve from 0.46664\n",
            "Epoch 148/200\n",
            "351/351 - 17s - loss: 0.3531 - accuracy: 0.8877 - val_loss: 0.4607 - val_accuracy: 0.8624\n",
            "\n",
            "Epoch 00148: val_loss improved from 0.46664 to 0.46074, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 149/200\n",
            "351/351 - 17s - loss: 0.3573 - accuracy: 0.8881 - val_loss: 0.4593 - val_accuracy: 0.8638\n",
            "\n",
            "Epoch 00149: val_loss improved from 0.46074 to 0.45929, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 150/200\n",
            "351/351 - 17s - loss: 0.3545 - accuracy: 0.8875 - val_loss: 0.5028 - val_accuracy: 0.8552\n",
            "\n",
            "Epoch 00150: val_loss did not improve from 0.45929\n",
            "Epoch 151/200\n",
            "351/351 - 17s - loss: 0.3550 - accuracy: 0.8877 - val_loss: 0.4803 - val_accuracy: 0.8596\n",
            "\n",
            "Epoch 00151: val_loss did not improve from 0.45929\n",
            "Epoch 152/200\n",
            "351/351 - 17s - loss: 0.3570 - accuracy: 0.8855 - val_loss: 0.4978 - val_accuracy: 0.8526\n",
            "\n",
            "Epoch 00152: val_loss did not improve from 0.45929\n",
            "Epoch 153/200\n",
            "351/351 - 17s - loss: 0.3502 - accuracy: 0.8890 - val_loss: 0.4572 - val_accuracy: 0.8652\n",
            "\n",
            "Epoch 00153: val_loss improved from 0.45929 to 0.45717, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 154/200\n",
            "351/351 - 17s - loss: 0.3553 - accuracy: 0.8873 - val_loss: 0.4677 - val_accuracy: 0.8634\n",
            "\n",
            "Epoch 00154: val_loss did not improve from 0.45717\n",
            "Epoch 155/200\n",
            "351/351 - 17s - loss: 0.3546 - accuracy: 0.8885 - val_loss: 0.4578 - val_accuracy: 0.8710\n",
            "\n",
            "Epoch 00155: val_loss did not improve from 0.45717\n",
            "Epoch 156/200\n",
            "351/351 - 17s - loss: 0.3509 - accuracy: 0.8897 - val_loss: 0.4841 - val_accuracy: 0.8586\n",
            "\n",
            "Epoch 00156: val_loss did not improve from 0.45717\n",
            "Epoch 157/200\n",
            "351/351 - 17s - loss: 0.3501 - accuracy: 0.8891 - val_loss: 0.5154 - val_accuracy: 0.8498\n",
            "\n",
            "Epoch 00157: val_loss did not improve from 0.45717\n",
            "Epoch 158/200\n",
            "351/351 - 17s - loss: 0.3524 - accuracy: 0.8880 - val_loss: 0.4829 - val_accuracy: 0.8610\n",
            "\n",
            "Epoch 00158: val_loss did not improve from 0.45717\n",
            "Epoch 159/200\n",
            "351/351 - 17s - loss: 0.3474 - accuracy: 0.8906 - val_loss: 0.4924 - val_accuracy: 0.8590\n",
            "\n",
            "Epoch 00159: val_loss did not improve from 0.45717\n",
            "Epoch 160/200\n",
            "351/351 - 17s - loss: 0.3431 - accuracy: 0.8933 - val_loss: 0.4851 - val_accuracy: 0.8632\n",
            "\n",
            "Epoch 00160: val_loss did not improve from 0.45717\n",
            "Epoch 161/200\n",
            "351/351 - 17s - loss: 0.3487 - accuracy: 0.8903 - val_loss: 0.4710 - val_accuracy: 0.8632\n",
            "\n",
            "Epoch 00161: val_loss did not improve from 0.45717\n",
            "Epoch 162/200\n",
            "351/351 - 17s - loss: 0.3396 - accuracy: 0.8922 - val_loss: 0.4847 - val_accuracy: 0.8606\n",
            "\n",
            "Epoch 00162: val_loss did not improve from 0.45717\n",
            "Epoch 163/200\n",
            "351/351 - 17s - loss: 0.3436 - accuracy: 0.8917 - val_loss: 0.4686 - val_accuracy: 0.8628\n",
            "\n",
            "Epoch 00163: val_loss did not improve from 0.45717\n",
            "Epoch 164/200\n",
            "351/351 - 17s - loss: 0.3432 - accuracy: 0.8916 - val_loss: 0.5001 - val_accuracy: 0.8580\n",
            "\n",
            "Epoch 00164: val_loss did not improve from 0.45717\n",
            "Epoch 165/200\n",
            "351/351 - 17s - loss: 0.3456 - accuracy: 0.8885 - val_loss: 0.4663 - val_accuracy: 0.8656\n",
            "\n",
            "Epoch 00165: val_loss did not improve from 0.45717\n",
            "Epoch 166/200\n",
            "351/351 - 17s - loss: 0.3391 - accuracy: 0.8928 - val_loss: 0.4641 - val_accuracy: 0.8684\n",
            "\n",
            "Epoch 00166: val_loss did not improve from 0.45717\n",
            "Epoch 167/200\n",
            "351/351 - 17s - loss: 0.3421 - accuracy: 0.8939 - val_loss: 0.4635 - val_accuracy: 0.8662\n",
            "\n",
            "Epoch 00167: val_loss did not improve from 0.45717\n",
            "Epoch 168/200\n",
            "351/351 - 17s - loss: 0.3347 - accuracy: 0.8943 - val_loss: 0.4873 - val_accuracy: 0.8630\n",
            "\n",
            "Epoch 00168: val_loss did not improve from 0.45717\n",
            "Epoch 169/200\n",
            "351/351 - 17s - loss: 0.3407 - accuracy: 0.8920 - val_loss: 0.4898 - val_accuracy: 0.8606\n",
            "\n",
            "Epoch 00169: val_loss did not improve from 0.45717\n",
            "Epoch 170/200\n",
            "351/351 - 17s - loss: 0.3359 - accuracy: 0.8940 - val_loss: 0.4824 - val_accuracy: 0.8636\n",
            "\n",
            "Epoch 00170: val_loss did not improve from 0.45717\n",
            "Epoch 171/200\n",
            "351/351 - 17s - loss: 0.3368 - accuracy: 0.8933 - val_loss: 0.4952 - val_accuracy: 0.8614\n",
            "\n",
            "Epoch 00171: val_loss did not improve from 0.45717\n",
            "Epoch 172/200\n",
            "351/351 - 17s - loss: 0.3377 - accuracy: 0.8934 - val_loss: 0.4679 - val_accuracy: 0.8660\n",
            "\n",
            "Epoch 00172: val_loss did not improve from 0.45717\n",
            "Epoch 173/200\n",
            "351/351 - 17s - loss: 0.3333 - accuracy: 0.8954 - val_loss: 0.4655 - val_accuracy: 0.8672\n",
            "\n",
            "Epoch 00173: val_loss did not improve from 0.45717\n",
            "Epoch 174/200\n",
            "351/351 - 17s - loss: 0.3329 - accuracy: 0.8951 - val_loss: 0.4643 - val_accuracy: 0.8688\n",
            "\n",
            "Epoch 00174: val_loss did not improve from 0.45717\n",
            "Epoch 175/200\n",
            "351/351 - 17s - loss: 0.3358 - accuracy: 0.8935 - val_loss: 0.4506 - val_accuracy: 0.8698\n",
            "\n",
            "Epoch 00175: val_loss improved from 0.45717 to 0.45062, saving model to model.100epochs.hdfs\n",
            "INFO:tensorflow:Assets written to: model.100epochs.hdfs/assets\n",
            "Epoch 176/200\n",
            "351/351 - 17s - loss: 0.3319 - accuracy: 0.8954 - val_loss: 0.4828 - val_accuracy: 0.8646\n",
            "\n",
            "Epoch 00176: val_loss did not improve from 0.45062\n",
            "Epoch 177/200\n",
            "351/351 - 17s - loss: 0.3293 - accuracy: 0.8968 - val_loss: 0.4838 - val_accuracy: 0.8642\n",
            "\n",
            "Epoch 00177: val_loss did not improve from 0.45062\n",
            "Epoch 178/200\n",
            "351/351 - 17s - loss: 0.3302 - accuracy: 0.8967 - val_loss: 0.4906 - val_accuracy: 0.8598\n",
            "\n",
            "Epoch 00178: val_loss did not improve from 0.45062\n",
            "Epoch 179/200\n",
            "351/351 - 17s - loss: 0.3290 - accuracy: 0.8967 - val_loss: 0.4643 - val_accuracy: 0.8626\n",
            "\n",
            "Epoch 00179: val_loss did not improve from 0.45062\n",
            "Epoch 180/200\n",
            "351/351 - 17s - loss: 0.3264 - accuracy: 0.8986 - val_loss: 0.4736 - val_accuracy: 0.8640\n",
            "\n",
            "Epoch 00180: val_loss did not improve from 0.45062\n",
            "Epoch 181/200\n",
            "351/351 - 17s - loss: 0.3319 - accuracy: 0.8960 - val_loss: 0.4904 - val_accuracy: 0.8622\n",
            "\n",
            "Epoch 00181: val_loss did not improve from 0.45062\n",
            "Epoch 182/200\n",
            "351/351 - 17s - loss: 0.3282 - accuracy: 0.8975 - val_loss: 0.4614 - val_accuracy: 0.8708\n",
            "\n",
            "Epoch 00182: val_loss did not improve from 0.45062\n",
            "Epoch 183/200\n",
            "351/351 - 17s - loss: 0.3299 - accuracy: 0.8974 - val_loss: 0.4753 - val_accuracy: 0.8654\n",
            "\n",
            "Epoch 00183: val_loss did not improve from 0.45062\n",
            "Epoch 184/200\n",
            "351/351 - 17s - loss: 0.3265 - accuracy: 0.8978 - val_loss: 0.4617 - val_accuracy: 0.8696\n",
            "\n",
            "Epoch 00184: val_loss did not improve from 0.45062\n",
            "Epoch 185/200\n",
            "351/351 - 17s - loss: 0.3235 - accuracy: 0.8998 - val_loss: 0.4644 - val_accuracy: 0.8708\n",
            "\n",
            "Epoch 00185: val_loss did not improve from 0.45062\n",
            "Epoch 186/200\n",
            "351/351 - 17s - loss: 0.3232 - accuracy: 0.8990 - val_loss: 0.4718 - val_accuracy: 0.8658\n",
            "\n",
            "Epoch 00186: val_loss did not improve from 0.45062\n",
            "Epoch 187/200\n",
            "351/351 - 17s - loss: 0.3199 - accuracy: 0.9001 - val_loss: 0.4552 - val_accuracy: 0.8690\n",
            "\n",
            "Epoch 00187: val_loss did not improve from 0.45062\n",
            "Epoch 188/200\n",
            "351/351 - 17s - loss: 0.3226 - accuracy: 0.8977 - val_loss: 0.4945 - val_accuracy: 0.8616\n",
            "\n",
            "Epoch 00188: val_loss did not improve from 0.45062\n",
            "Epoch 189/200\n",
            "351/351 - 17s - loss: 0.3190 - accuracy: 0.9006 - val_loss: 0.4541 - val_accuracy: 0.8692\n",
            "\n",
            "Epoch 00189: val_loss did not improve from 0.45062\n",
            "Epoch 190/200\n",
            "351/351 - 17s - loss: 0.3155 - accuracy: 0.9014 - val_loss: 0.4799 - val_accuracy: 0.8676\n",
            "\n",
            "Epoch 00190: val_loss did not improve from 0.45062\n",
            "Epoch 191/200\n",
            "351/351 - 17s - loss: 0.3210 - accuracy: 0.8988 - val_loss: 0.4657 - val_accuracy: 0.8704\n",
            "\n",
            "Epoch 00191: val_loss did not improve from 0.45062\n",
            "Epoch 192/200\n",
            "351/351 - 17s - loss: 0.3219 - accuracy: 0.8993 - val_loss: 0.4737 - val_accuracy: 0.8650\n",
            "\n",
            "Epoch 00192: val_loss did not improve from 0.45062\n",
            "Epoch 193/200\n",
            "351/351 - 17s - loss: 0.3196 - accuracy: 0.9008 - val_loss: 0.4681 - val_accuracy: 0.8656\n",
            "\n",
            "Epoch 00193: val_loss did not improve from 0.45062\n",
            "Epoch 194/200\n",
            "351/351 - 17s - loss: 0.3184 - accuracy: 0.9010 - val_loss: 0.4783 - val_accuracy: 0.8660\n",
            "\n",
            "Epoch 00194: val_loss did not improve from 0.45062\n",
            "Epoch 195/200\n",
            "351/351 - 17s - loss: 0.3142 - accuracy: 0.9010 - val_loss: 0.4749 - val_accuracy: 0.8714\n",
            "\n",
            "Epoch 00195: val_loss did not improve from 0.45062\n",
            "Epoch 196/200\n",
            "351/351 - 17s - loss: 0.3147 - accuracy: 0.9017 - val_loss: 0.4851 - val_accuracy: 0.8660\n",
            "\n",
            "Epoch 00196: val_loss did not improve from 0.45062\n",
            "Epoch 197/200\n",
            "351/351 - 17s - loss: 0.3140 - accuracy: 0.9029 - val_loss: 0.4546 - val_accuracy: 0.8706\n",
            "\n",
            "Epoch 00197: val_loss did not improve from 0.45062\n",
            "Epoch 198/200\n",
            "351/351 - 17s - loss: 0.3166 - accuracy: 0.9017 - val_loss: 0.4522 - val_accuracy: 0.8702\n",
            "\n",
            "Epoch 00198: val_loss did not improve from 0.45062\n",
            "Epoch 199/200\n",
            "351/351 - 17s - loss: 0.3129 - accuracy: 0.9016 - val_loss: 0.4940 - val_accuracy: 0.8610\n",
            "\n",
            "Epoch 00199: val_loss did not improve from 0.45062\n",
            "Epoch 200/200\n",
            "351/351 - 17s - loss: 0.3100 - accuracy: 0.9029 - val_loss: 0.4725 - val_accuracy: 0.8644\n",
            "\n",
            "Epoch 00200: val_loss did not improve from 0.45062\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "542LMt2Uk56z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ede790c-b29a-4c99-b1d8-97f83ae87b89"
      },
      "source": [
        "scores = model.evaluate(x_test,y_test,batch_size=128,verbose=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 1s 7ms/step - loss: 0.5448 - accuracy: 0.8566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RS_N5ZWlMQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc28306-8d86-4426-cb6e-ce6054e7dcbf"
      },
      "source": [
        "print('\\n Test Set Accuracy:: %.3f'%(scores[1]*100))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Test Set Accuracy:: 85.660\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrh-UOEscBs-"
      },
      "source": [
        "test = model.predict(x_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvyTScoQcHVf",
        "outputId": "46ea503c-e1b6-4e56-8d5e-ac99d5f6d327"
      },
      "source": [
        "print(test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2.71663971e-08 5.03930729e-04 1.11181493e-04 ... 3.49186244e-08\n",
            "  2.54911583e-06 1.43238663e-06]\n",
            " [1.60131287e-06 2.90130451e-02 9.75122240e-12 ... 3.49749786e-12\n",
            "  9.70959306e-01 2.60288452e-05]\n",
            " [8.08830828e-06 2.79266834e-02 3.88203958e-09 ... 4.69971440e-09\n",
            "  9.70979989e-01 1.08497695e-03]\n",
            " ...\n",
            " [6.67088884e-11 1.16191523e-09 5.43186616e-06 ... 1.34633126e-06\n",
            "  1.33797293e-10 1.99606038e-08]\n",
            " [1.03201666e-04 9.99894857e-01 9.87946365e-08 ... 6.81406986e-10\n",
            "  3.50086424e-07 4.79720427e-07]\n",
            " [4.29769111e-12 9.44420236e-12 4.12058105e-12 ... 9.99958038e-01\n",
            "  1.31118996e-15 8.26638935e-15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jBvVUmvcJKb",
        "outputId": "1c1592a1-14e3-4358-c4be-dec0c2b1cf18"
      },
      "source": [
        "print(test.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJUy1HF_cMmV",
        "outputId": "572a7c11-4242-41b9-ead6-06fca0e62459"
      },
      "source": [
        "print(np.argmax(test,axis=1))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 8 8 ... 5 1 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOWIafGIcaYP",
        "outputId": "336ecdf2-0aa3-4c9a-87e6-816674b8bd93"
      },
      "source": [
        "print(np.argmax(y_test,axis=1))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 8 8 ... 5 1 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "TVjL9z02MPMz",
        "outputId": "bbdc9127-19ae-4a64-dc82-c6d3d8bb6f0f"
      },
      "source": [
        "# Confusion Matrix:\n",
        "from sklearn.metrics import confusion_matrix\n",
        "class_labels = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
        "confusion = confusion_matrix(np.argmax(y_test,axis=1),np.argmax(model.predict(x_test),axis=1))\n",
        "\n",
        "plt.imshow(confusion,cmap=plt.cm.Blues)\n",
        "plt.colorbar()\n",
        "indexes = np.arange(len(class_labels))\n",
        "\n",
        "indexes = np.arange(len(class_labels))\n",
        "for i in indexes:\n",
        "    for j in indexes:\n",
        "        plt.text(j, i, confusion[i, j])\n",
        "plt.xticks(indexes, class_labels, rotation=90)\n",
        "plt.xlabel('Predicted label')\n",
        "plt.yticks(indexes, class_labels)\n",
        "plt.ylabel('True label')\n",
        "plt.title('Confusion matrix')\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWuzgq5pcY0L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}